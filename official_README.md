# Benchmarking CNNs for gesture recognition on embedded devices equipped by robots
```diff
- Note: Code and models will be added after the acceptance of our eponymous work.
```
Implementation of the framework used in [Benchmarking CNNs for gesture recognition on embedded devices equipped by robots](link). The workflow is developed to perform a benchmarking focusing not only on the accuracy but also on the computational burden, involving two different architectures (2D and 3D), with two different backbones (MobileNet, ResNeXt) and four types of input modalities (RGB, Depth, Optical Flow, Motion History Image) and their combinations.
Il sistema effettua il gesture recognition seguendo the following schema.

![alt text](https://github.com/stefanobini/gesture_recognition/blob/main/workflow.png)

Please cite the following [paper](link) if you feel this repository useful.
```bibtext
@article{bini2022benchmarking,
  author={Bini, Stefano and Greco, Antonio and Saggese, Alessia and Vento, Mario},
  booktitle={2022 31th IEEE International Conference on Robot   Human Interactive Communication (RO-MAN)},
  title={Benchmarking CNNs for gesture recognition on embedded devices equipped by robots},
  year={2022},
  volume={},
  number={},
  pages={},
  doi={}
```
