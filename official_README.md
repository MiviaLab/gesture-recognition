# Benchmarking CNNs for gesture recognition on embedded devices equipped by robots
```diff
- Note: Code and models will be added after the acceptance of our eponymous work.
```
Implementation of the framework used in [Benchmarking CNNs for gesture recognition on embedded devices equipped by robots](link). The workflow is developed to perform a benchmarking focusing not only on the accuracy but also on the computational burden, involving two different architectures (2D and 3D), with two different backbones (MobileNet, ResNeXt) and four types of input modalities (RGB, Depth, Optical Flow, Motion History Image) and their combinations.
Il sistema effettua il gesture recognition seguendo the following schema.

![alt text](https://github.com/stefanobini/gesture_recognition/blob/main/workflow.png)
